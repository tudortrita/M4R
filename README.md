# M4R
MSci Mathematics Imperial College final year research project and dissertation supervised by [Dr. Andrew Duncan](http://wwwf.imperial.ac.uk/~aduncan/).

Project graded at 80.3% (First class).

### Abstract:

Dimensionality reduction techniques are becoming increasingly important as a step in
processing large amounts of data efficiently. By reducing the dimension of data, we can
gain rewards in terms of computational speed, model complexity as well as easy
visualisation and interpretation of data. We can also reduce the amount of noise present
in data.

In this report, we explore a technique for guided dimension reduction through
maximising the dependence between our transformed input variables and our output
variables. We quantify the degree of dependence through the Hilbert-Schmidt
independence criterion (HSIC). With this method we aim to learn the transformation
that finds directions in our input variable space which are most dependent to our output
data. We then compare the effectiveness of this method with two other guided or
supervised dimension reduction methods; partial least squares (PLS) and gradient-based
Kernel Dimension Reduction (gKDR).


Finally, we explore using the HSIC method for anomaly detection on a dataset from
social media analytics and compare performance with PLS and gKDR.
